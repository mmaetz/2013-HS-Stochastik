\chapter{Zufallsvariable und Wahrscheinlichkeitsverteilung}
\label{kap2}
Ergebnisse eines physikalischen Versuchs (Zufallsexperiment) sind oft Zahlen (Messungen). Diese werden als Beobachtung von so genannten Zufallsvariablen interpertiert, d.h. beobachtet wird nicht das $\omega$ welches bei einem Zufallsexperiment herauskommnt, sondern die Werte aller beobachtetetn Zufallsvariablen.
\section{Definition einer Zufallsvariablen}
Eine Zufallsvariable $X$ ist ein Zuffalsexperiment mit möglichen Werten in $\mathbb{R}$, bzw. in einer Teilmenge von $\mathbb{R}$, z.B. $\mathbb{N}_0=\{0,1,\ldots\}$. Deren Wert ist im Voraus nicht bekannt, sondern hängt vom Ergebnis eines Zufallsexperiments ab. Mathematisch ist eine Zufallsvariable einfach nur eine Abbildung von $\Omega$ nach $\mathbb{R}$:
\begin{align*}
	X:\Omega&\to \mathbb{R},\\
	\omega &\mapsto X(\omega).
\end{align*}
Das heisst wenn das Ergebnis $\omega$ herauskommt, nimmt die Zufallsvariable den Wert $X(\omega)$ an.
\begin{bspl}[Wert einer zuf. gez. Jasskarte.]
	Sei $\Omega=\{\text{Jasskarten}\}$; ein $\omega\in\Omega$ ist z.B. ein Schilten-As; Zufallsvariable $X$:
	\begin{align*}
		\text{As irgendeiner Farbe}&\mapsto 11\\
		\text{König irgendeiner Farbe}&\mapsto 4\\
		\text{\glqq Brettchen\grqq\ irgendeiner Farbe}&\mapsto 0.
	\end{align*}
\end{bspl}
\section{Wahrscheinlichkeitsverteilung auf $\mathbb{R}$}
Eine Zufallsvariable $X$ legt eine Wahrscheinlichkeit $Q$ auf $\mathbb{R}$ fest, die segenannte \emph{Verteilung} von $X$:
\begin{align*}
\gdls
	Q(B)&=\p \!\left(\left\{  \omega; X(\omega)\in B  \right\}\right)\\
	&= \p (X\in B)
\end{align*}
\begin{bspl}[Wert einer zuf. gez. Jk. Forts.]
	In obigem Beispiel ist beispielsweise 
	\begin{align*}
		Q(11)&=\p (\text{As irgendeiner Farbe})\\
		&=\frac{4}{36}.
	\end{align*}
\end{bspl}
Die \emph{kumulative Verteilungsfunktion} ist definiert als
\begin{align*}
	F(b)&=\p (X\leq b)\\
	&=Q\!\left( ( -\infty,b ]  \right).
\end{align*}
Sie enthält dieselbe Information wie die Verteilung $Q(\cdot)$, ist aber einfacher darzustellen. Die Umkehrung der Verteilungsfunktion stellen di esogenannten Quantile dar, für $\alpha\in (0,1)$ ist das $\alpha$\emph{-Quantil von} $X$ definiert als das kleinste $x\in \mathbb{R}$ für welches $F(x)\geq \alpha$ gilt, also
\begin{align*}
	q_{\alpha}&\coloneqq q(\alpha)\\
	&\coloneqq \min\{x\in \mathbb{R} \mid  F(x)\geq \alpha\}
\end{align*}
Es gilt 
\begin{align*}
	F(q_{\alpha}) = \alpha
	\intertext{bzw. äquivalent dazu}
	q_{\alpha}=F^{-1}(\alpha).
\end{align*}
Das $\frac{1}{2}$-Quantil von $X$ heisst auch \emph{Median von} $X$.
\section{Diskrete und stetige Zufallsvariablen}
Eine Zufallsvariable $X$ heisst \emph{diskret}, falls die Menge $W$ der möglichen Werte von $X$ endlich oder abzählbar ist. Zum Beispiel $W=\{0,1,2,\ldots,100\}$ oder $W=\mathbb{N}_0=\{0,1,2,\ldots\}$. Die Verteilung einer diskreten Zufallsvariablen ist festgelegt durch die Angabe der sogenannten \emph{Wahrscheinlichkeitsfunktion}:
\begin{align*}
	p(x)&\coloneqq \p(X=x), \qquad x\in W.
	\intertext{Offensichtlich ist die kumulative Verteilungsfunktion eine Treppenfunktion mit Sprüngen an den Stellen $x\in W$ mit Sprunghöhen $p(x)$, also nicht stetig. Ferner gilt}
	Q(B)&=\sum_{x\in B}^{}p(x).
\end{align*}
Eine Zufallsvariable $X$ heisst \emph{stetig} falls die Menge der möglichen Werte $W$ ein Intervall enthält. Zum Beispiel $W=[0,1]$ oder $W=\mathbb{R}$.
\section{Erwartungswert und Varianz}
Eine Verteilung einer Zufallsvariablen $X$ kann durch mindestens zwei Kennzahlen zusammengefasst werden, eine für die Lage (der Erwartungswert $E(X)=\mu_X$) und eine für die Streuung (die Standardabweichung $\sigma_X$).
Der \emph{Erwartungswert} einer diskreten Zufallsvariable $X$ ist definiert durch
\begin{align*}
	%\label{erwartungswert}
	\mu_X &= E(X) \nonumber\\
	&\coloneqq \sum\limits_{x \in W}x p(x)\nonumber
	\intertext{Für den Erwartungswert einer tranformierten diskreten Zufallsvariable $Y = f(X)$ ergibt sich daraus:}
	E(Y) &= E(f(X))\nonumber\\
	&= \sum\limits_{x \in W} f(x)p(x)\nonumber
	\intertext{Die \emph{Varianz} einer diskreten Zufallsvariable $X$ ist definiert durch:}
	V(X) &\coloneqq E((X-E(X))^2)\\
	&=\sum\limits_{x\in W} (x-\mu_X)^2 p(x)
	\intertext{Die \emph{Standardabweichung} ist die Wurzel aus der Varianz, d.h.}
	\sigma_X &= \sqrt{V(X)}.\nonumber \\
	\intertext{Folgende Rechenregeln sind nützlich:}
	E(a+bX) &= a+bE(X), \ a,b \in \mathbb{R}\nonumber\\
	V(X) &= E(X^2) - E(X)^2\nonumber\\
	V(a+bX) &= b^2V(X)\nonumber
	\label{eq:varianz}
\end{align*}
In der frequentistischen Interpretation ist der Erwartungswert eine Idealisierung des arithmetischen Mittels der Werte einer Zufallsvariablen bei vielen Wiederholungen.
\section{Die wichtigsten diskreten Verteilungen}
\subsection{Binomialverteilung}
Die \emph{Binomialverteilung} $\mathrm{Bin}(n,p)$ ist die Verteilung der Anzahl Erfolge bei $n$ unabhängigen Wiederholungen eines Experiments mit Erfolgswahrscheinlichkeit $p$.
\begin{align*}
	W &= {0,1,\cdots,n}\\
	p(x) &= {a\choose b} p^x(1-p)^{n-x}\\
	E(X) &= np\\
	\sigma_X &= \sqrt{np(1-p)}
\end{align*}
\subsection{Poissonverteilung}
Die \emph{Poissonverteilung} $\mathrm{Poi}(\lambda)$ ist eine Approximation der Binomialverteilung für grosses $n$ und kleines $p$, mit $np = \lambda$. Die Anzahl Ausfälle einer Komponente oder eines Systems in einem interval der Länge $t$ ist oft in erster Näherung Poisson-verteilt mit Parameter $\lambda t$.
\begin{align*}
	W &= {0,1,\cdots}\\
	p(x) &= e^{-\lambda} \frac{\lambda^x}{x!}\\
	E(X) &= \lambda\\
	\sigma_X &= \sqrt{\lambda}
\end{align*}
\subsection{Geometrische Verteilung}
Die \emph{geometrische Verteilung} $\mathrm{Geo}(p)$ ist die Verteilung der Anzahl Wiederholungen bis ein Ereignis mit Wahrscheinlichkeit $p$ eintritt.
\begin{align*}
	W &= {1,2,\cdots}\\
	p(x) &= p(1-p)^{x-1}\\
	E(X) &= \frac{1}{p}\\
	\sigma_X &= \frac{\sqrt{1-p}}{p}
\end{align*}
