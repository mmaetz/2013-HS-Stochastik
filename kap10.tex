\chapter{Punktschätzungen}
\label{kap10}
Wir betrachten folgendes Problem: Gegeben sei wieder eine Zufallsvariable $X$ von der wir zwar die Art der Vertilung kennen, aber nicht den dazugehörigen Parameter (Vektor) $\theta$. basierend auf $n$ unabhängigen Beobachtungen $x_1,\ldots,x_n$ von $X$, die wir wie immer als eine realisierung der i.i.d. Zufallsvariablen $X_1,\ldots,X_n$ (mit derselben Verteilung wie $X$) interpretieren soll nun der unbekannte Parameter $\theta$ geschätzt werden. Sei $\theta$ ein reeller Parameter einer Wahrscheinlichkeitsverteilung auf $\mathbb{R}$, ein \emph{Schätzer für} $\theta$ (zur Stichprobengrösse $n$) ist eine Funktion $\hat{\theta}: \mathbb{R}^n\to \mathbb{R}$ von den $\mathbb{R}^n$ 
\begin{align*}
	\hat{\theta}&=\hat{\theta}(x_1,\ldots,x_n)
	\intertext{oder als Zufallsvariable interpretiert}
	\hat{\theta}&=\hat{\theta}(X_1,\ldots,X_n).
\end{align*}
Man beachte dass bei der Verwendung von griechischen buchstaben keine Unterscheidung mehr zwischen Realisierung (Kleinbuchstaben) und Zufallsvariable (Grossbuchstaben) gemacht wird.
\section{Momentenmethode}
Das $k$\emph{-te Moment von} $X$ ist definiert durch 
\begin{align}
	\mu_k&\coloneqq \E(X^k),\nonumber
	\intertext{das erste Moment entspricht also dem Erwartungswert. Die Momentenmethode nimmt an, dass wir den unbekannten Parametervetor $(\theta_1,\ldots,\theta_r)$ durch die ersten $p$ Momente von $X$ ausdrücken können, d.h. allgemein}
	\theta_j&=g_j(\mu_1,\ldots,\mu_p), \qquad j=1,\ldots,r,
	\label{eq:above}
\end{align}
die $j$-te Komponente von $\theta$ ist also gegeben durch die Funktion $g_j:\mathbb{R}^p\to\mathbb{R}$.

Ausgehend von Gleichung \ref{eq:above} werden nun die wahren $\mu_k$ ersetzt durch deren Schätzungen 
\begin{align*}
	\hat{\mu}_k&\coloneqq\frac{1}{n}\sum_{i=1}^{n}x_{i}^{k},
	\intertext{wenn man diese noch als Zufallsvariable schreibt, dann erhält man einen Momentenschätzer für die einzelnen Komponenten von $\theta$ durch}
	\hat{\theta}_j&=g_j(\hat{\mu}_(,\ldots,\hat{\mu}_p),& j&=1,\ldots,r;\\
	\hat{\mu}_k&=\frac{1}{n}\sum_{i=1}^{n}X_{i}^{k},& k&=1,\ldots,p.
\end{align*}
\emph{Rezeptatrige Vorgagnsweise:} Gegeben ist eine Zufallsvariable $X$ deren Verteilung von einem unbekannten (zu schätzenden) Parameter $\theta$ abhängt. Man berechnet zunächst das erste Moment von $X$, wenn dieses von $\theta$ abhängt, dann löst man die Gleichung nach $\theta$ auf, d.h. man schreibt $\theta$ als Funktion des ersten Momentes, dann wird das erste Moment durch dessen Schätzer ersetzt und man erhält einen Momentenschätzer für $\theta$. Falls das erste Moment nicht von $\theta$ abhängt berechnet man das zweite Moment usw. Es ist aber auch möglich, dass sämtliche Momente von $\theta$ abhängen, man erhält dann mehrere (unterschiedliche) Momentenschätzer für $\theta$.
\begin{bspl}
	Sei $X\sim\poi(\lambda)$ mit unbekanntem Parameter $\lambda$. Das erste Moment von $X$ ist
	\begin{align*}
		\E(X)&=\lambda,
		\intertext{oder anders geschrieben,}
		\lambda&=\mu_1,
		\intertext{nun wird $\mu_1$ durch dessen Schätzung}
		\hat{\mu}_1&=\frac{1}{n}\sum_{i=1}^{n}x_i
		\intertext{ersetzt, als Zufallsvariable geschrieben erhält man einen Momentenschätzer für $\lambda$ durch}
		\hat{\lambda}&=\hat{\mu}_1=\overline{X}_n=\frac{1}{n}\sum_{i=1}^{n}X_i.
	\end{align*}
\end{bspl}
Einen weiteren Momentenschätzer fur $\lambda$ erhalten wir durch Berechnung des zweiten Momentes von 
\begin{align*}
	X:\mu_2&=\E(X^2)=\V(X)+\E(X)^2=\lambda+\mu_{1}^{2}
	\intertext{woraus nun}
	\lambda&=\mu_2-\mu_{1}^{2}
	\intertext{folgt und wir erhalten den Momentenschätzer}
	\hat{\lambda}&=\hat{\mu}_2-\hat{\mu}_{1}^{2}\\
	&=\frac{1}{n}\sum_{i=1}^{n}X_{i}^{2}\\
	&=\frac{n-1}{n}S_{n}^{2}
\end{align*}
Man zieht aber $\hat{\lambda}=\overline{X}_n$ vor, denn dies ist auch der sogenannte Maximum-Likelihood Schätzer, welcher im Allgemeinen genauer ist.

Der Momentenschätzer ist einfach, aber nicht immer die optimale (im Sinne einer zu definierenden besten Genauigkeit für den unbekannten Parameter) Methode. Überdies ist der Momentenschätzer nicht eindeutig, wie wir am obigen Beispiel gesehen haben.
\section{Maximum-Likelihood Schätzer}
Sei zunächst $X$ diskret. Um die Abhängigkeit vom unbekannten Parameter $\theta$ zu betonen bezeichnen wir die Wahrscheinlichkeitsfunktion $p_{X}$ von $X$ mit $p_{\theta}$. Die Wahrscheinlichkeit, dass tatsächlich das Ereignis $\left\{ X_1=x_1,\ldots,X_n=x_n \right\}$ eintritt ist wegen der Unabhängigkeit und Gleichverteilung gegeben durch
\begin{align*}
	L(\theta)&\coloneqq p_{X_1,\ldots,X_n}(x_1,\ldots,x_n)\\
	&=\prod_{i=1}^{n}p_{\theta}(x_i)\\
	&=p_{\theta}(x_1)\cdot \cdots \cdot p_{\theta}(x_n),
\end{align*}
dies ist die sogenannte \emph{Likelihoodfunktion (zur gegebenen Stichprobe $x_1,\ldots,x_n$)}. Die \emph{Maximum-Likelihood Methode} basiert nun darauf diese Wahrscheinlichkeit zu maximieren, also jenen Parameter $\theta$ zu finden für den die Wahrscheinlichkeit dass die gegebene Stichprobe $x_1,\ldots,x_n$ eintritt am grössten (maximal) ist, daher der Name Maximum-Likelihood.

Da der Logarithmus monoton wachsend ist, kann man äquivalent zu obiger Maximierungsaufgabe auch den Logarithmus maximieren, was meist (aber nicht unbedintg immer!) einfacher ist. Die log-Likelihoodfunktion ist definiert durch
\begin{align*}
	l(\theta)&\coloneqq \log L(\theta)\\
	&=\sum_{i=1}^{n}\log p_{\theta}(x_i)\\
	&=\log p_{\theta}(x_1),\ldots,\log p_{\theta}(x_n).
\end{align*}
Die Maximierungsaufgabe lößt man wie aus der Analysis bekannt durch Ableiten (nach dem Parameter $\theta$) und Nullsetzen. Um die Abhängigkeit von der Stichprobe $x_1,\ldots,x_n$ zu betonen schreibt man auch
\begin{align*}
	l(\theta;x_(,\ldots,x_n)&\coloneqq \log p_{\theta} (x_1)+\cdots +\log p_{\theta}(x_n),
	\intertext{man muss dann die Gleichung}
	\pdv{}{\theta}l (\theta;x_1,\ldots,x_n)&=0
	\intertext{nach $\theta$ auflösen und erhält das Ergebnis}
	\hat{\theta}=\hat{\theta}(x_1,\ldots,x_n)
	\shortintertext{bzw. als Zufallsvariable ausgedrückt}
	\hat{\theta}&=\hat{\theta}(X_1,\ldots,X_n)
\end{align*}
als allgemeinen Maximum-Likelihood Schätzer von $\theta$ (zum Stichprobenumfang $n$).

Im stetigen Fall geht im Wesentlichen alles analog und man braucht nur den Buchstaben $p$ durch $f$ und \glqq Wahrscheinlichkeit\grqq \ durch \glqq Wahrscheinlichkeitsdichte\grqq \ zu ersetzen, d.h. statt Wahrscheinlichkeiten hat man dann Dichten, und es wird jener Parameter $\theta$ gesucht für den die gemeinseme Dichte der $X_1,\ldots,X_n$ an der Stelle $x_1,\ldots,x_n$ am grössten ist.
\begin{bspl}[Fortsetzung]
	$X\sim \poi(\lambda)$. Die Wahrscheinlichkeitsfunktion ist
	\begin{align*}
		p_{\lambda}(x)&=\frac{\lambda^x}{x!}e^{-\lambda},&&x\in\mathbb{N},
		\intertext{die log-Likelihoodfunktion ist somit}
		l(\lambda)=\sum_{i=1}^{n}(x_i\log (\lambda)-\log(x_i!)-\lambda)\\
		&=\sum_{i=1}^{n}(x_i\log (\lambda)-\lambda)-C,\\
		C&=\sum_{i=1}^{n}\log(x_i!)
	\end{align*}
\end{bspl}
