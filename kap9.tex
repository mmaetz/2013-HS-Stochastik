\chapter{Statistik bei normalverteilten Daten}
Wir betrachten folgende Situation. Gegeben sind $n$ Beobachtungen (Realisierungen) $x_1,\ldots,x_n$ von Zufallsvariablen $X_1,\ldots,X_n$ i.i.d. $\sim \mathcal{N}(\mu,\sigma^2)$. Typischerweise sind dies $n$ Messungen einer unbekannten Grösse $\mu$, und $\sigma$ gibt an, wie genau die Messungen sind. Die Annahme der Normalverteilung wird meist mit dem Zentralen Grenzwertsatz begründet. Ausserdem nehmen wir noch an, dass es keine Beeinflussungen zwischen den einzelnen Beobachtungen gibt, so dass die Unabhängigkeit der Zufallsvariablen gerechtfertigt erscheint.

Wir möchten aus $x_1,\ldots,x_n$ Rückschlüsse auf die unbekannten Parameter $\mu$ und $\sigma$ ziehen. Wie zuvor geht es um die drei Fragestellungen Punktschätzung, Test für einen vorgegebenen Wert (Sollwert) und Vertrauensintervall (Bereich von plausiblen Werten). Weil $\mu$ meist von grösserem Interesse ist als $\sigma$, behandeln wir die letzten beiden Fragestellungen nur für $\mu$.
\section{Schätzungen}
Die Punktschätzungen sind:
\begin{align}
	\hat{\mu}&=\overline{X}_n=\frac{1}{n}\sum_{i=1}^{n}\\
	\hat{\sigma}^2&=S_{n}^{2}=\frac{1}{n-1}\sum_{i=1}^{n}\left( X_i-\hat{\mu} \right)^2
	\label{eq:schaetzer}
\end{align}
Diese Schätzungen sind Funktionen von Zufallsvariablen, also wieder zufällig und im allgemeinen verschieden vom unbekannten wahren Wert. Die realisierten Werte dieser Schätzung (den Wert den man berechnen kann) erhält man indem die Zufallsvariable $X_i$ mit deren realisiertem Wert $x_i$ ersetzt wird.

Der Erwartungswert der Schätzer ist
\begin{align*}
	\E(\hat{\mu})&=\mu,\\
	\E(\hat{\sigma}^2)&=\sigma^2.
\end{align*}
(Dies ist der Grund für den Nenner $n-1$.)
\section{Testen}
\label{sec9.2}
Wir haben $n$ voneinander unabhängige Beobachtungen $x_1,\ldots,x_n$ einer Zufallsvariable $X\sim \mathcal{N}(\mu,\sigma^2)$, interpretiert als eine Beobachtung der i.i.d. Zufallsvariablen $X_1,\ldots,X_n$ mit der selben Verteilung wie $X$. Wir fixieren je nach Problemstellung ein $\mu_0\in\mathbb{R}$ und wollen die Nullhypothese $H_0:\mu=\mu_0$ gegen eine der möglichen Alternativen $H_A:\mu\neq \mu_0$, $H_A:\mu<\mu_0$ bzw. $H_A:\mu>\mu_0$ testen. Dabei unterscheiden wir zwei Fälle: Die Streuung $\sigma$ ist bekannt, dann verwenden wir den sogenannten $z$-Test, oder die Streuung $\sigma$ ist unbekannt. (Dann muss sie aus den beobachteten Daten geschätzt werden) , in diesem Fall ergibt sich der sogenannte $t$-Test.
\subsection{z-Test ($\sigma$ bekannt)}
Wir nehmen an, dass $\sigma$ bekannt ist. Die Teststatistik ist definiert als die Zufallsvariable
\begin{align*}
	T\coloneqq \sqrt{n}\frac{\overline{X}_n-\mu_0}{\sigma},
	\shortintertext{wobei $\overline{X}_n$ den Schätzer für den Mittelwert aus Gl. \ref{eq:schaetzer} darstellt. Wir lehnen für eine gegebene Realisierung}
	t=\sqrt{n}(\overline{x}_n-\mu_0)/\sigma,
	\shortintertext{von $T$ je nach Alternative $H_A$ die Nullhypothese}
	 H_0&:\mu=\mu_0
	\shortintertext{ab.}
\end{align*}
\begin{align}
	\intertext{\colorlet{rulecolor}{black}\rule{\columnwidth}{0.1ex}}
	\begin{split}\label{eq:ztest1}
		\abs{t}&\geq z_{1-\alpha/2},\\
		\Leftrightarrow t &\in VB_{\alpha}=(-\infty,z_{\alpha/2}]\cup [z_{1-\alpha/2},\infty),\\
			H_A&:\mu\neq\mu_0.
	\end{split}\\
	\intertext{\colorlet{rulecolor}{black}\rule{\columnwidth}{0.1ex}}
	\begin{split}\label{eq:ztest2}
		t&\geq z_{1-\alpha},
		\Leftrightarrow t \in [z_{1-\alpha},\infty),\\
			H_A&:\mu>\mu_0.
	\end{split}\\
	\intertext{\colorlet{rulecolor}{black}\rule{\columnwidth}{0.1ex}}
	\begin{split}\label{eq:ztest3}
		t&\leq z_{\alpha},
		\Leftrightarrow t \in (-\infty,z_{\alpha}],\\
		H_A&:\mu<\mu_0.
	\end{split}
	\intertext{\colorlet{rulecolor}{black}\rule{\columnwidth}{0.1ex}}\nonumber
\end{align}
Die Begründung für Eq. \ref{eq:ztestdinimuetter} ist wie folgt, die Teststatistik $T$ ist unter der Nullhypothese $\mathcal{N}(0,1)$-verteilt, woraus sich der Fehler 1. Art, sofort zu
\begin{gather*}
	\p_{\mu=\mu_0}(\abs{T}\geq z_{1-\alpha/2})
\end{gather*}
ergibt, also genau wie es sein sollte. Das $(1-\alpha)$-Vertrauensintervall für den Parameter $\mu$ ist gegeben durch
\begin{gather*}
	I_{1-\alpha}=\left[ \overline{X}_n-\frac{\sigma}{\sqrt{n}}z_{1-\alpha/2},\overline{X}_n+\frac{\sigma}{\sqrt{n}}z_{1-\alpha/2} \right],
\end{gather*}
da es von den $X_1,\ldots,X_n$ abhängt ist es zufällig, für eine gegebene Beobachtung $\overline{x}_n$ wird dann $\overline{X}_n$ einfach durch $\overline{x}_n$ ersetzt um die Realisierung des Vertrauensintervalls zur Stichprobe $x_1,\ldots,x_n$ zu erhalten. Das Vertrauensintervall ist so definiert, dass es den wahren Wert von $\mu$ mit Wahrscheinlichkeit $1-\alpha$ \glqq einfängt\grqq: Eine kurze Umformung ergibt, dass das Ereignis 
\begin{align*}
	\left\{ \mu\in I \right\}&=\left\{ \omega\in\Omega\mid \mu\in I(\omega) \right\}\\
	\intertext{gegeben ist durch}
	\left\{ \mu\in I \right\}&=\left\{ \abs{\sqrt{n}\,\frac{\overline{X}_n-\mu}{\sigma}}\leq z_{1-\alpha/2} \right\}
	\intertext{und wegen}
	\sqrt{n}\, \frac{\overline{X}_n-\mu}{\sigma}&\sim \mathcal{N}(0,1)
	\intertext{ergibt sich sofort}%ergibt sich aus dem ausgelassenen Bild sofort
	\p(\mu\in I)&=\p\!\left(\abs{\sqrt{n}\, \frac{\overline{X}_n-\mu}{\sigma}}\leq z_{1-\alpha/2}  \right)\\
	&=1-\alpha
\end{align*}
Der P-Wert zu einer gegebenen Realisierung $t$ der Teststatistik $T$ errechnet sich im zweiseitigen Fall zu
\begin{align*}
	\p_{\mu=\mu_0}(\abs{T}\geq\abs{t})&=2\p_{\mu=\mu_0}\\
	&=2\left( 1-\Phi(\abs{t}) \right)
\end{align*}
\subsection{t-Test ($\sigma$ unbekannt)}
Kenntnis von $\sigma$, welche für den z-Test benötigt wird, ist in der Praxis meist unrealistisch. Wenn wir $\sigma$ nicht kennen, ersetzen wir es durch den Schätzer $S_n$ aus Gleichung \ref{eq:schaetzer}. Die Teststatistik ist dann
\begin{align*}
	T&\coloneqq\sqrt{n}\, \frac{\overline{X}_n-\mu_0}{S_n}.
	\intertext{Im Gegensatz zur Teststatistik beim z-Test ist sie hier $t$-verteilt mit Freiheitsgrad $n-1$, das $\alpha$-Quantil der $t$-Verteilung mit Freiheitsgrad $n$ wird mit $t_{n,\alpha}$ bezeichnet. Wir lehnen für eine gegebene Realisierung}
	t&=\sqrt{n}\, \frac{\overline{x}_n-\mu}{s_n},
	\shortintertext{von $T$ je nach Alternative $H_A$ die Nullhypothese}
H_0&:\mu=\mu_0
\end{align*}
ab, falls
\begin{align}
	\intertext{\colorlet{rulecolor}{black}\rule{\columnwidth}{0.1ex}}
	\begin{split}\label{eq:ztestdinimuetter}
		\abs{t}&\geq t_{n-1,1-\alpha/2},\\
	\Leftrightarrow t &\in VB_{\alpha}=(-\infty,t_{n-1,\alpha/2}]\cup [t_{n-1,1-\alpha/2},\infty),\\
			H_A&:\mu\neq\mu_0.
	\end{split}\\
	\intertext{\colorlet{rulecolor}{black}\rule{\columnwidth}{0.1ex}}
	\begin{split}\label{eq:ztest2}
		t&\geq t_{n-1,1-\alpha},
		\Leftrightarrow t \in [t_{n-1,1-\alpha},\infty),\\
			H_A&:\mu>\mu_0.
	\end{split}\\
	\intertext{\colorlet{rulecolor}{black}\rule{\columnwidth}{0.1ex}}
	\begin{split}\label{eq:ztest3}
		t&\leq t_{n-1,\alpha},
	\Leftrightarrow t \in (-\infty,t_{n-1,\alpha}],\\
		H_A&:\mu<\mu_0.
	\end{split}
	\intertext{\colorlet{rulecolor}{black}\rule{\columnwidth}{0.1ex}}\nonumber
\end{align}
Das $\left(1 -\alpha \right)$-Vertrauensintervall ist gegeben durch
\begin{align*}
	&I_{1-\alpha}=\\&\left[ \overline{X}_n-\frac{S_n}{\sqrt{n}}t_{n-1,1-\alpha/2},\overline{X}_n+\frac{S_n}{\sqrt{n}}t_{n-1,1-\alpha/2} \right].
\end{align*}
Ausblick auf eine verwandte Methode in der Praxis: In der \emph{statistischen Qualitätskontrolle} wird in regelmässigen Abständen eine kleine Stichprobe vom Umfang $n$ aus dem Produktionsprozess gezogen, die Zielgrösse gemessen, gemittelt und gegen die Zeit aufgetragen. Fällt ein Mittelwert ausserhalb der Kontrollgrenzen \glqq Sollwert $\pm 3\sigma/\sqrt{n}$\grqq\ oder sind 9 aufeinandererfolgende Mittelwerte alle grösser oder alle kleiner als der Sollwert, dann ist der Produktionsprozess ausser Kontrolle.
\subsection{Macht eines Tests}
Ein statistischer Test kontrolliert direkt die Wahrscheinlichkeit eines Fehlers 1. Art via dem Signifikanzniveau $\alpha$:
\begin{align*}
	\p(\text{Fehler 1. Art})&=\p(\text{Test verwirft }H_0\text{ obschon }\\&\hphantom{=\p()}H_0\text{ stimmt })\\
	&\lessapprox\alpha.
\end{align*}
Die Wahrscheinlichkeit eines Fehlers 2. Art ist eine Funktion des Parameterwerts $\mu\in H_A$:
\begin{align*}
	\beta(\mu)&=\p(\text{Test akzeptiert }H_0\\&\hphantom{=\p()}\text{obschon ein }\mu\in H_A\text{ stimmt}).
	\intertext{Die Macht eines Tests ist definiert als}
	1-\beta(\mu)&=\p(\text{Test verwirft richtigerweise }\\&\hphantom{=\p()}H_0\text{ für ein }\mu\in H_A).
\end{align*}
Die Macht (englisch power) eines Tests beschreibt die Kapazität wie gut ein Test einen Parameter im bereich der Alternative richtigerweise entdecken kann. Die Macht kann deshalb als Gütemass gebraucht werden, um optimale Tests zu charakterisieren.

Man kann zeigen, dass der t-Test der optimale Test (bzgl. der Macht) unter allen möglichen Tests ist, \emph{falls} die Beobachtungen normalverteilt sind. Bei nicht-normalverteilten Beobachtungen können andere Tests (siehe Kaptiel \ref{sec11.2}) sehr viel besser sein als der t-Test.\\[1em]
\begin{tabular}[pos=ttcc]{cc|c|c|}
	\multicolumn{2}{c}{}&\multicolumn{2}{c}{Entscheidung}\\
	&\multicolumn{1}{c}{}&\multicolumn{1}{c}{$H_0$}&\multicolumn{1}{c}{$H_A$}\\
	\cline{3-4}
	\multirow{4}{*}{\rotatebox[]{90}{Wahrheit\quad}}\!\!\!&&kein Fehler&Fehler 1. Art\\
	&$H_0$\!\!&$\!\begin{aligned}p&=1-\alpha\\&=P_{H_0}(X\not\in V) \end{aligned}\!$&$\!\begin{aligned}p&=\alpha\\&=P_{H_0}(X\in V) \end{aligned}\!$\\
	\cline{3-4}
	&&Fehler 2. Art&kein Fehler\\
	&$H_A$\!\!&$\!\begin{aligned}p&=\beta\\&=P_{H_A}(X\not\in V) \end{aligned}\!$&$\!\begin{aligned}p&=1-\beta\\&=P_{H_A}(X\in V) \end{aligned}\!$\\
	\cline{3-4}
\end{tabular}

